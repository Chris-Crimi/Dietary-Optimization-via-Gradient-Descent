{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Food code</th>\n",
       "      <th>Main food description</th>\n",
       "      <th>WWEIA Category number</th>\n",
       "      <th>WWEIA Category description</th>\n",
       "      <th>Energy (kcal)</th>\n",
       "      <th>Protein (g)</th>\n",
       "      <th>Carbohydrate (g)</th>\n",
       "      <th>Sugars, total\\n(g)</th>\n",
       "      <th>Fiber, total dietary (g)</th>\n",
       "      <th>Total Fat (g)</th>\n",
       "      <th>...</th>\n",
       "      <th>20:1\\n(g)</th>\n",
       "      <th>22:1\\n(g)</th>\n",
       "      <th>18:2\\n(g)</th>\n",
       "      <th>18:3\\n(g)</th>\n",
       "      <th>18:4\\n(g)</th>\n",
       "      <th>20:4\\n(g)</th>\n",
       "      <th>20:5 n-3\\n(g)</th>\n",
       "      <th>22:5 n-3\\n(g)</th>\n",
       "      <th>22:6 n-3\\n(g)</th>\n",
       "      <th>Water\\n(g)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11000000</td>\n",
       "      <td>Milk, human</td>\n",
       "      <td>9602</td>\n",
       "      <td>Human milk</td>\n",
       "      <td>70</td>\n",
       "      <td>1.03</td>\n",
       "      <td>6.89</td>\n",
       "      <td>6.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.38</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>87.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11100000</td>\n",
       "      <td>Milk, NFS</td>\n",
       "      <td>1004</td>\n",
       "      <td>Milk, reduced fat</td>\n",
       "      <td>52</td>\n",
       "      <td>3.33</td>\n",
       "      <td>4.83</td>\n",
       "      <td>4.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>88.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11111000</td>\n",
       "      <td>Milk, whole</td>\n",
       "      <td>1002</td>\n",
       "      <td>Milk, whole</td>\n",
       "      <td>61</td>\n",
       "      <td>3.27</td>\n",
       "      <td>4.63</td>\n",
       "      <td>4.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>88.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11112110</td>\n",
       "      <td>Milk, reduced fat (2%)</td>\n",
       "      <td>1004</td>\n",
       "      <td>Milk, reduced fat</td>\n",
       "      <td>50</td>\n",
       "      <td>3.36</td>\n",
       "      <td>4.90</td>\n",
       "      <td>4.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>89.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11112210</td>\n",
       "      <td>Milk, low fat (1%)</td>\n",
       "      <td>1006</td>\n",
       "      <td>Milk, lowfat</td>\n",
       "      <td>43</td>\n",
       "      <td>3.38</td>\n",
       "      <td>5.18</td>\n",
       "      <td>4.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>89.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5619</th>\n",
       "      <td>99997802</td>\n",
       "      <td>Tomatoes as ingredient in omelet</td>\n",
       "      <td>9999</td>\n",
       "      <td>Not included in a food category</td>\n",
       "      <td>25</td>\n",
       "      <td>1.11</td>\n",
       "      <td>5.48</td>\n",
       "      <td>3.42</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.23</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>92.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5620</th>\n",
       "      <td>99997804</td>\n",
       "      <td>Other vegetables as ingredient in omelet</td>\n",
       "      <td>9999</td>\n",
       "      <td>Not included in a food category</td>\n",
       "      <td>39</td>\n",
       "      <td>3.25</td>\n",
       "      <td>5.74</td>\n",
       "      <td>2.73</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>89.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5621</th>\n",
       "      <td>99997810</td>\n",
       "      <td>Vegetables as ingredient in curry</td>\n",
       "      <td>9999</td>\n",
       "      <td>Not included in a food category</td>\n",
       "      <td>52</td>\n",
       "      <td>1.81</td>\n",
       "      <td>11.60</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5622</th>\n",
       "      <td>99998130</td>\n",
       "      <td>Sauce as ingredient in hamburgers</td>\n",
       "      <td>9999</td>\n",
       "      <td>Not included in a food category</td>\n",
       "      <td>272</td>\n",
       "      <td>1.34</td>\n",
       "      <td>17.14</td>\n",
       "      <td>13.08</td>\n",
       "      <td>0.6</td>\n",
       "      <td>22.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.133</td>\n",
       "      <td>11.810</td>\n",
       "      <td>1.682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>55.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5623</th>\n",
       "      <td>99998210</td>\n",
       "      <td>Industrial oil as ingredient in food</td>\n",
       "      <td>9999</td>\n",
       "      <td>Not included in a food category</td>\n",
       "      <td>892</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.024</td>\n",
       "      <td>30.114</td>\n",
       "      <td>1.698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5624 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Food code                     Main food description  \\\n",
       "0      11000000                               Milk, human   \n",
       "1      11100000                                 Milk, NFS   \n",
       "2      11111000                               Milk, whole   \n",
       "3      11112110                    Milk, reduced fat (2%)   \n",
       "4      11112210                        Milk, low fat (1%)   \n",
       "...         ...                                       ...   \n",
       "5619   99997802          Tomatoes as ingredient in omelet   \n",
       "5620   99997804  Other vegetables as ingredient in omelet   \n",
       "5621   99997810         Vegetables as ingredient in curry   \n",
       "5622   99998130         Sauce as ingredient in hamburgers   \n",
       "5623   99998210      Industrial oil as ingredient in food   \n",
       "\n",
       "      WWEIA Category number       WWEIA Category description  Energy (kcal)  \\\n",
       "0                      9602                       Human milk             70   \n",
       "1                      1004                Milk, reduced fat             52   \n",
       "2                      1002                      Milk, whole             61   \n",
       "3                      1004                Milk, reduced fat             50   \n",
       "4                      1006                     Milk, lowfat             43   \n",
       "...                     ...                              ...            ...   \n",
       "5619                   9999  Not included in a food category             25   \n",
       "5620                   9999  Not included in a food category             39   \n",
       "5621                   9999  Not included in a food category             52   \n",
       "5622                   9999  Not included in a food category            272   \n",
       "5623                   9999  Not included in a food category            892   \n",
       "\n",
       "      Protein (g)  Carbohydrate (g)  Sugars, total\\n(g)  \\\n",
       "0            1.03              6.89                6.89   \n",
       "1            3.33              4.83                4.88   \n",
       "2            3.27              4.63                4.81   \n",
       "3            3.36              4.90                4.89   \n",
       "4            3.38              5.18                4.96   \n",
       "...           ...               ...                 ...   \n",
       "5619         1.11              5.48                3.42   \n",
       "5620         3.25              5.74                2.73   \n",
       "5621         1.81             11.60                3.25   \n",
       "5622         1.34             17.14               13.08   \n",
       "5623         0.00              0.00                0.00   \n",
       "\n",
       "      Fiber, total dietary (g)  Total Fat (g)  ...  20:1\\n(g)  22:1\\n(g)  \\\n",
       "0                          0.0           4.38  ...      0.040      0.000   \n",
       "1                          0.0           2.14  ...      0.002      0.000   \n",
       "2                          0.0           3.20  ...      0.004      0.000   \n",
       "3                          0.0           1.90  ...      0.002      0.000   \n",
       "4                          0.0           0.95  ...      0.001      0.000   \n",
       "...                        ...            ...  ...        ...        ...   \n",
       "5619                       1.6           0.23  ...      0.000      0.000   \n",
       "5620                       1.4           0.39  ...      0.000      0.000   \n",
       "5621                       2.2           0.19  ...      0.000      0.000   \n",
       "5622                       0.6          22.85  ...      0.106      0.133   \n",
       "5623                       0.0         100.00  ...      0.322      0.024   \n",
       "\n",
       "      18:2\\n(g)  18:3\\n(g)  18:4\\n(g)  20:4\\n(g)  20:5 n-3\\n(g)  \\\n",
       "0         0.374      0.052        0.0      0.026          0.000   \n",
       "1         0.074      0.008        0.0      0.003          0.000   \n",
       "2         0.115      0.013        0.0      0.004          0.001   \n",
       "3         0.061      0.007        0.0      0.003          0.000   \n",
       "4         0.033      0.004        0.0      0.001          0.000   \n",
       "...         ...        ...        ...        ...            ...   \n",
       "5619      0.089      0.004        0.0      0.000          0.000   \n",
       "5620      0.174      0.001        0.0      0.000          0.000   \n",
       "5621      0.052      0.012        0.0      0.000          0.000   \n",
       "5622     11.810      1.682        0.0      0.015          0.000   \n",
       "5623     30.114      1.698        0.0      0.000          0.000   \n",
       "\n",
       "      22:5 n-3\\n(g)  22:6 n-3\\n(g)  Water\\n(g)  \n",
       "0             0.000          0.000       87.50  \n",
       "1             0.001          0.000       88.92  \n",
       "2             0.002          0.000       88.10  \n",
       "3             0.001          0.000       89.10  \n",
       "4             0.000          0.000       89.70  \n",
       "...             ...            ...         ...  \n",
       "5619          0.000          0.000       92.57  \n",
       "5620          0.000          0.000       89.67  \n",
       "5621          0.000          0.000       85.59  \n",
       "5622          0.000          0.002       55.97  \n",
       "5623          0.000          0.000        0.00  \n",
       "\n",
       "[5624 rows x 69 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load USDA database & transform it into the form we need\n",
    "food_database = pd.read_excel(\"2019-2020 FNDDS At A Glance - FNDDS Nutrient Values.xlsx\", \n",
    "                              header = 1 #set column headers\n",
    "                              )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current thought:\n",
    "- amount of foods are inputs\n",
    "- quality rates are weights (e.g., amount of calories per 100gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.27147371 3.43186411]]\n",
      "[[ 5.70333513 11.40667026  7.9994605 ]]\n",
      "[[4.94680305e-01 1.97872122e+00 2.91059849e-07]]\n"
     ]
    }
   ],
   "source": [
    "#very basic prototype optimization algorithm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#intialzie amounts\n",
    "amounts = np.array([[1.0,1.0]])\n",
    "\n",
    "#rows represent food, cols represent qualities\n",
    "quality_rates = np.array([[1,2,.5],\n",
    "                          [1,2,2]])\n",
    "\n",
    "learning_rate = .001\n",
    "\n",
    "#goal amounts\n",
    "targets = [5,10,8]\n",
    "\n",
    "outputs, errors, amountss = [], [], []\n",
    "\n",
    "stop_time = 1000\n",
    "for i in range(stop_time):\n",
    "    output = np.dot(amounts, quality_rates)\n",
    "    outputs.append(output)\n",
    "    #squared error is the loss function\n",
    "    error = (output - targets)**2\n",
    "    errors.append(error)\n",
    "    #derivative of loss wrt to output\n",
    "    dloss = 2*(output - targets)\n",
    "    #print(dloss)\n",
    "\n",
    "    dmax = targets.copy\n",
    "    dmax = np.ones_like(output)\n",
    "    dmax[output >= targets] = 0 \n",
    "    #print(dmax)\n",
    "\n",
    "    dfoods = dloss * dmax\n",
    "    #print(dfoods)\n",
    "\n",
    "    #deriv wrt amounts is quality rate\n",
    "    dinputs = np.dot(dfoods, quality_rates.T)\n",
    "    #print(dinputs)\n",
    "\n",
    "    amounts += -learning_rate * dinputs\n",
    "    amountss.append(amounts)\n",
    "\n",
    "\n",
    "print(amounts)\n",
    "print(output)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to fully implement for food\n",
    "- we are going to minimize cost, while trying to meet thresholds for other items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "food_data = pd.read_excel(r\"C:\\Users\\Chris\\Desktop\\Diet Data\\Diet Optimization.xlsx\", sheet_name=\"For Python Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_rates = food_data.iloc[0:20,6:].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.000e+00, 2.035e+03, 1.530e+02, 5.000e+01, 2.000e+02, 3.000e+01,\n",
       "        1.000e+03, 4.000e+02, 9.000e+02, 2.400e+00, 1.300e+00, 9.000e+01,\n",
       "        1.500e+01, 1.500e+01, 1.200e+02, 9.000e-01, 8.000e+00, 4.000e+02,\n",
       "        1.100e+01, 7.000e+02, 5.500e+01, 3.400e+03, 1.500e+03, 5.500e+02,\n",
       "        1.200e+00, 1.300e+00, 1.600e+01, 1.600e+00]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_values = food_data.iloc[24:,2].to_numpy().astype(float).reshape(1,-1)\n",
    "target_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.  , 0.3 , 0.3 , 5.  , 1.5 , 1.  , 0.5 , 1.5 , 0.25, 0.5 , 0.5 ,\n",
       "        0.5 , 0.5 , 0.1 , 1.4 , 1.  , 2.1 , 0.1 , 2.3 , 0.21]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_limits = food_data.iloc[24:44,6].to_numpy().reshape(1,-1)\n",
    "food_limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.9 , 0.  , 0.  , 0.  , 2.25, 0.2 ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_req = food_data.iloc[24:44,9].to_numpy().reshape(1,-1)\n",
    "food_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "OverflowError",
     "evalue": "(34, 'Result too large')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-0d088a57b7d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamounts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquality_rates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtarget_values_non_z\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtarget_values_non_z\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0merror\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0merror\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mtarget_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOverflowError\u001b[0m: (34, 'Result too large')"
     ]
    }
   ],
   "source": [
    "#amounts = np.random.rand(1,20) * 10\n",
    "amounts = np.zeros((1,20))\n",
    "#amounts[0,0] = 14\n",
    "learning_rate = 1\n",
    "#starting_learning_rate = .01\n",
    "learning_rate_decay = 0#0.0000001\n",
    "errors = []\n",
    "\n",
    "dinputs_momentums = np.zeros_like(amounts)\n",
    "cache = np.zeros_like(amounts)\n",
    "epsilon = 1e-7 \n",
    "\n",
    "beta_1 = .9\n",
    "beta_2 = .999\n",
    "\n",
    "lambda_penalty = .05\n",
    "penalty_cache = np.zeros_like(amounts)\n",
    "\n",
    "target_values_non_z = target_values.copy()\n",
    "target_values_non_z[0,0] = 1e-7\n",
    "\n",
    "for i in range(10000):\n",
    "\n",
    "    outputs = np.dot(amounts, quality_rates)\n",
    "    error = ((outputs - target_values_non_z)/target_values_non_z)**2         \n",
    "    error[0,0] = 0 #we still calculate derivative, but exclude the error for cost\n",
    "    error[0,2:][outputs[0,2:] >= target_values[0,2:]] = 0.0\n",
    "    errors.append(np.sum(error))\n",
    "\n",
    "    penalty_deriv = np.zeros_like(amounts)\n",
    "    penalty_deriv[amounts.copy() > food_limits.copy()] = 1\n",
    "    penalty_deriv[amounts.copy() < food_req.copy()] = -1\n",
    "    penalty_deriv = penalty_deriv * food_limits.copy()\n",
    "\n",
    "    dloss = 2*(outputs - target_values_non_z)/target_values_non_z**2\n",
    "    dmax = np.ones_like(outputs)\n",
    "\n",
    "    #we are looking to stay calorie target, and minimize costs, so want to avoid those\n",
    "    #but once all the other ones have hit their goals, set them to 0\n",
    "    #dmax[0,1] = 0 if outputs[0,1] <= target_values[0,1] else dmax[0,1]\n",
    "    dmax[0,0] = 0\n",
    "    dmax[0,2:][outputs[0,2:] >= target_values[0,2:]] = 0.0\n",
    "    \n",
    "    dfoods = dloss * dmax\n",
    "    dinputs = np.dot(dfoods, quality_rates.T)\n",
    "\n",
    "    #momentum\n",
    "    dinputs_momentums = dinputs_momentums * beta_1 + dinputs.astype(float) * (1 - beta_1)\n",
    "    correted_momentums = dinputs_momentums / (1 - beta_1 ** (i + 1))\n",
    "\n",
    "    cache = cache * dinputs.astype(float) ** 2 #beta_2 + (1-beta_2) * dinputs.astype(float) ** 2\n",
    "    corrected_cahce = cache #/ (1 - beta_2 ** (i + 1))\n",
    "    penalty_cache += penalty_deriv **2\n",
    "    \n",
    "    amounts += -learning_rate * (correted_momentums / (np.sqrt(cache) + epsilon)  + lambda_penalty * penalty_deriv * 1/np.sqrt(penalty_cache+epsilon))\n",
    "\n",
    "    learning_rate = learning_rate * (1 / (1 + learning_rate_decay * i))\n",
    "\n",
    "results = np.dot(amounts, quality_rates)\n",
    "print(results)\n",
    "print(results - target_values)\n",
    "print(\"final error:\", errors[-1])\n",
    "plt.plot(errors[0:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. , -2.3,  0. ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penalty_deriv = np.zeros_like(amounts)\n",
    "penalty_deriv[amounts.copy() > food_limits.copy()] = 1\n",
    "penalty_deriv[amounts.copy() < food_req.copy()] = -1\n",
    "penalty_deriv = penalty_deriv * food_limits.copy()\n",
    "penalty_deriv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.06917488, 0.29789464, 0.2239849 , 2.91855552, 1.47326141,\n",
       "        0.95078389, 0.48694994, 1.47945588, 0.2478282 , 0.4768447 ,\n",
       "        0.48264619, 0.47516851, 0.48899912, 0.09696531, 1.22059628,\n",
       "        0.98756274, 1.98092781, 0.09659181, 2.16728902, 0.20701223]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0,\n",
       "        0.0]], dtype=object)"
      ]
     },
     "execution_count": 1174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes from this go around:\n",
    "- have been successful in closely matching excel output\n",
    "- requires averaging gradients (dividing dloss by sum of dmax)\n",
    "- without cost constraint we get very close to solver results\n",
    "- with cost constaint it is close, but a bit more different\n",
    "- ideal learning rate  learning_rate = .00001\n",
    "\n",
    "Possible Improvements\n",
    "- RMS prop?/ADA grad?? - i think the key will be some type of per-parameter learning rate, as the parameters have very differnet sizes, thus a global rate does not work well. For example, applying the same learning rate to calories and omega3s doesn't work because calories has much higher magnitude values than omega3\n",
    "- momentum\n",
    "- adaptive gradient\n",
    "- learning rate decay\n",
    "\n",
    "Features that I don't think are very helpful (pre-adagrad/RMS prop):\n",
    "- gradient normalization - does not seem to make a huge difference. I think this is not very beneficial because there is nothing really to smooth out. We are stochastically descending the gradient and don't have batches. \n",
    "- learning rate decay - does not seem to help. The varying magnitude of parameters remove the effectiveness of learning rate decay because we are using a uniform decay rate. Thus suffers from same issue as uniform learning rate\n",
    "- momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After adding adagrad & rmsprop\n",
    "- we get to a local minimum quite quickly, which is close to excel solver solution => and if parameters are set accordinly, can get very similar solutions between RMSprop and ada grad\n",
    "- ada grad does best with learning rate of 1, RMS .001. Same lrd\n",
    "- perhaps try adam next. But I am starting to think this is probably the most optimal solution we will get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further Updates:\n",
    "- have added Adam, it works ok, I think a little better than plain RMS prop/ada\n",
    "- instead of resetting amounts each time, I am now trying to do constrained optimization\n",
    "- it does not work very well right now. Possible improvements/Considerations:\n",
    "1) Don't think it should be included within the cache or momentum EWMAs\n",
    "2) The penalty term, lambda, should be scaled somehow, because we are dealing with values of different magnitudes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further thoughts:\n",
    "- Combine relative squared error with adagrad? There might be something here, but garlic keeps getting stuck too high, so need to do some more work around penalization\n",
    "- need a better way to make penalization relative. Current method is to scale it by 1/(1+i*iteraion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current Best Parameters for Squared Error\n",
    "- lr = 1, decay = 0, adagrad, 1/(i + 1) penalty scaling, penalty term = 20, beta = .99; however we do run into an issue where chia seeds are higher than desired by about 5g\n",
    "- new best are below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13.99229856399297 2036.128210358288 181.17861695042538\n",
      "  61.09182137485768 196.0422201955804 35.03674465977529 998.4184579845352\n",
      "  411.61047855241543 1303.4252919262087 7.230408807165557\n",
      "  4.5854561432534675 260.5952978785556 14.91096766864887\n",
      "  13.509640543792571 691.8554479172179 1.6285378348635609\n",
      "  13.036332039289162 631.2322092222271 13.836355721316908\n",
      "  2572.600398300314 254.39863142899483 4385.489580835273\n",
      "  3181.0094768236527 547.746971886002 1.7278817433823437\n",
      "  3.0653309054340703 52.382476675348926 2.6227576231613736]]\n",
      "[[13.99229856399297 1.1282103582880154 28.17861695042538\n",
      "  11.09182137485768 -3.9577798044196015 5.036744659775287\n",
      "  -1.5815420154648336 11.61047855241543 403.42529192620873\n",
      "  4.830408807165558 3.2854561432534677 170.59529787855558\n",
      "  -0.0890323313511292 -1.490359456207429 571.8554479172179\n",
      "  0.7285378348635608 5.036332039289162 231.23220922222708\n",
      "  2.8363557213169077 1872.6003983003138 199.39863142899483\n",
      "  985.489580835273 1681.0094768236527 -2.2530281139979706\n",
      "  0.5278817433823437 1.7653309054340702 36.382476675348926\n",
      "  1.0227576231613735]]\n",
      "final error: 26.429328048779265\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#amounts = np.random.rand(1,20) * 10\n",
    "amounts = np.zeros((1,20))\n",
    "#amounts[0,0] = 14\n",
    "learning_rate = 1\n",
    "#starting_learning_rate = .01\n",
    "learning_rate_decay = 0#0.0000000001\n",
    "errors = []\n",
    "\n",
    "dinputs_momentums = np.zeros_like(amounts)\n",
    "cache = np.zeros_like(amounts)\n",
    "epsilon = 1e-7 \n",
    "\n",
    "beta_1 = .99\n",
    "beta_2 = .9\n",
    "\n",
    "lambda_penalty = .05\n",
    "penalty_cache = np.zeros_like(amounts)\n",
    "\n",
    "for i in range(100000):\n",
    "\n",
    "    outputs = np.dot(amounts, quality_rates)\n",
    "    error = (outputs - target_values)**2\n",
    "    error[0,0] = 0\n",
    "    error[0,2:][outputs[0,2:] >= target_values[0,2:]] = 0.0\n",
    "    errors.append(np.sum(error))\n",
    "\n",
    "    penalty_deriv = np.zeros_like(amounts)\n",
    "    penalty_deriv[amounts.copy() > food_limits.copy()] = 1\n",
    "    penalty_deriv[amounts.copy() < food_req.copy()] = -1\n",
    "    penalty_deriv = penalty_deriv * food_limits.copy()\n",
    "\n",
    "    dloss = 2*(outputs - target_values)\n",
    "    dmax = np.ones_like(outputs)\n",
    "\n",
    "    #we are looking to stay calorie target, and minimize costs, so want to avoid those\n",
    "    #but once all the other ones have hit their goals, set them to 0\n",
    "    #dmax[0,1] = 0 if outputs[0,1] <= target_values[0,1] else dmax[0,1]\n",
    "    #dmax[0,0] = 0\n",
    "    dmax[0,2:][outputs[0,2:] >= target_values[0,2:]] = 0.0\n",
    "    \n",
    "    dfoods = dloss * dmax\n",
    "    dinputs = np.dot(dfoods, quality_rates.T)\n",
    "\n",
    "    #momentum\n",
    "    dinputs_momentums = dinputs_momentums * beta_1 + dinputs.astype(float) * (1 - beta_1)\n",
    "    correted_momentums = dinputs_momentums / (1 - beta_1 ** (i + 1))\n",
    "\n",
    "    cache = cache + dinputs.astype(float) ** 2#* beta_2 + (1-beta_2) * dinputs.astype(float) ** 2\n",
    "    corrected_cache = cache #/ (1 - beta_2 ** (i + 1))\n",
    "    penalty_cache += penalty_deriv **2\n",
    "    \n",
    "    amounts += -learning_rate * (correted_momentums / (np.sqrt(corrected_cache) + epsilon)  + lambda_penalty * penalty_deriv * 1/np.sqrt(penalty_cache+epsilon))\n",
    "\n",
    "    learning_rate = learning_rate * (1 / (1 + learning_rate_decay * i))\n",
    "\n",
    "results = np.dot(amounts, quality_rates)\n",
    "print(results)\n",
    "print((results - target_values))\n",
    "print(\"final error:\", errors[-1])\n",
    "plt.plot(errors[5000:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0.3, 0. , 0. , 0. , 0. , 0.5, 1.5, 0. , 0. , 0. , 0. , 0. ,\n",
       "        0.1, 0. , 0. , 2.1, 0. , 0. , 0. ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penalty_deriv = np.zeros_like(amounts)\n",
    "penalty_deriv[amounts.copy() > food_limits.copy()] = 1\n",
    "penalty_deriv[amounts.copy() < food_req.copy()] = -1\n",
    "penalty_deriv = penalty_deriv * food_limits.copy()\n",
    "penalty_deriv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.94039465, 0.30011588, 0.15233841, 2.80127075, 1.49979092,\n",
       "        0.99974944, 0.50003206, 1.50000348, 0.24948297, 0.49972262,\n",
       "        0.49944849, 0.49985972, 0.49966698, 0.10000229, 0.60701259,\n",
       "        0.99964463, 2.26052232, 0.0999446 , 2.29904132, 0.20999295]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
